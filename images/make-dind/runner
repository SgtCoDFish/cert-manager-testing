#!/usr/bin/env bash

# Copyright 2023 The Kubernetes Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# TIP: use https://github.com/kubernetes/test-infra/blob/29db47ec636660a9d547e29e55d16efb27ce57b4/images/bootstrap/runner.sh#L28 as
# inspiration for some of the hacks and tricks that we use in this file.

# generic runner script, handles DIND, etc.

# Check if the job has opted-in to local caching and if so check for a cache and
# copy the cache to prepopulate the local cache. After the job is done, change the
# latest cache directory to the local cache directory.
export LOCAL_CACHE_ENABLED=${LOCAL_CACHE_ENABLED:-false}

if [[ "${LOCAL_CACHE_ENABLED}" == "true" ]]; then
    if [[ "${SHARED_CACHE_DIR}" == "" ]]; then
        echo >&2 "LOCAL_CACHE_ENABLED was enabled but SHARED_CACHE_DIR is empty."
        exit 1
    fi

    if [[ "${LOCAL_CACHE_DIR}" == "" ]]; then
        echo >&2 "LOCAL_CACHE_ENABLED was enabled but LOCAL_CACHE_DIR is empty."
        exit 1
    fi

    # Convert local cache directory to absolute path and re-export it.
    LOCAL_CACHE_DIR="$(pwd)/${LOCAL_CACHE_DIR}"
    export LOCAL_CACHE_DIR

    if [[ -f "${SHARED_CACHE_DIR}/latest" ]]; then
        echo "## Local cache [restore]: found latest cache directory."

        # Obtain the name of the latest cache directory.
        latest_cache_dir=$(cat "${SHARED_CACHE_DIR}/latest")

        mkdir -p "${LOCAL_CACHE_DIR}"

        # Copying the latest cache to our local cache ...
        rsync -avv --inplace --delete "${latest_cache_dir}/." "${LOCAL_CACHE_DIR}"

        echo "## Local cache [restore]: provisioned ${LOCAL_CACHE_DIR}"
    else
        echo "## Local cache [restore]: no latest cache directory found."
    fi
fi

# Check if the job has opted-in to docker in docker and if so start the docker daemon
export DOCKER_IN_DOCKER_ENABLED=${DOCKER_IN_DOCKER_ENABLED:-false}

if [[ "${DOCKER_CONFIG:-}" != "" ]]; then
    if [[ "${DOCKER_IN_DOCKER_ENABLED}" != "true" ]]; then
        echo >&2 "DOCKER_CONFIG was requested but DOCKER_IN_DOCKER_ENABLED is not true."
        exit 1
    fi

    echo "## Docker [start]: A writable DOCKER_CONFIG was requested."
    tmpdir="$(mktemp -d)"
    ln -s "${DOCKER_CONFIG}/config.json" "${tmpdir}/config.json"
    export DOCKER_CONFIG="${tmpdir}"
fi

if [[ "${EXTRA_DOCKER_OPTS:-}" != "" ]]; then
    if [[ "${DOCKER_IN_DOCKER_ENABLED}" != "true" ]]; then
        echo >&2 "EXTRA_DOCKER_OPTS was requested but DOCKER_IN_DOCKER_ENABLED is not true."
        exit 1
    fi

    echo "## Docker [start]: Extra docker opts were requested."
    echo "DOCKER_OPTS=\"\${DOCKER_OPTS} ${EXTRA_DOCKER_OPTS}\"" >>/etc/default/docker
fi

if [[ "${DOCKER_IN_DOCKER_ENABLED}" == "true" ]]; then
    echo "## Docker [start]: Initializing Docker in Docker."

    # Fix ulimit issue
    sed -i 's|ulimit -Hn|ulimit -n|' /etc/init.d/docker || true

    service docker start
    # The service may be marked as ready but the Docker socket may not be
    # ready yet.
    WAIT_N=0
    MAX_WAIT=5
    while true; do
        # docker ps -q should only work if the daemon is ready
        docker ps -q >/dev/null 2>&1 && break
        if [[ ${WAIT_N} -lt ${MAX_WAIT} ]]; then
            WAIT_N=$((WAIT_N + 1))
            echo "## Docker [start]: Waiting for docker to be ready, sleeping for ${WAIT_N} seconds."
            sleep ${WAIT_N}
        else
            echo "## Docker [start]: Reached maximum attempts, not waiting any longer..."
            break
        fi
    done

    echo "## Docker [start]: Done setting up docker in docker."
fi

# Disable error exit so we can run post-command cleanup.
set +o errexit

printf '\n%.0s' {1..3}; echo
echo "###########################################"
echo "############### Start test ################"
echo "###########################################"
echo "### JOB_NAME: ${JOB_NAME}"
echo "### JOB_TYPE: ${JOB_TYPE}"
echo "### PROW_JOB_ID: ${PROW_JOB_ID}"
echo "### REPO_OWNER: ${REPO_OWNER}"
echo "### REPO_NAME: ${REPO_NAME}"
echo "### PULL_REFS: ${PULL_REFS}"
echo "###########################################"
echo "### LOCAL_CACHE_ENABLED: ${LOCAL_CACHE_ENABLED}"
echo "### DOCKER_IN_DOCKER_ENABLED: ${DOCKER_IN_DOCKER_ENABLED}"
echo "###########################################"
echo ""

start=$(date +%s.%N)

# Run the actual job.
"$@" &
WRAPPED_COMMAND_PID=$!

# Bash does not "trikle down" UNIX signals. If the Bash script receives SIGINT
# coming from Prow due to the 2 hours timeout being hit, and that the above
# command "$@" is running, then SIGINT won't be passed down to the "$@" command.
# To work around that, we trap SIGINT and SIGTERM and pass then down
# explicitely. The reasons for handling both SIGTERM and SIGINT is detailed in
# the following table:
#
#  |                          Reason                          |   Signal    |
#  |----------------------------------------------------------|-------------|
#  | The 2 hours Prow timeout has been reached                | SIGINT [1]  |
#  | Google Cloud VM preempted using ACPI shutdown            | SIGTERM [2] |
#  | GKE worker removed due to scale down using ACPI shutdown | SIGTERM [2] |
#
#  [1]: https://github.com/kubernetes/test-infra/blob/ee1e7c8/prow/entrypoint/run.go#L242
#  [2]: https://unix.stackexchange.com/questions/499761/what-signal-is-sent-to-running-programs-scripts-on-shutdown
#
trap 'kill -s INT "$WRAPPED_COMMAND_PID" || true' INT
trap 'kill -s TERM "$WRAPPED_COMMAND_PID" || true' TERM

wait $WRAPPED_COMMAND_PID
EXIT_VALUE=$?

end=$(date +%s.%N)

echo ""
echo "###########################################"
echo "################ End test #################"
echo "###########################################"
echo "## EXIT_VALUE: ${EXIT_VALUE}"
echo "## Elapsed Time: $((end-start)) seconds"
echo "###########################################"
printf '\n%.0s' {1..3}; echo

# cleanup after job
if [[ "${DOCKER_IN_DOCKER_ENABLED}" == "true" ]]; then
    echo "## Docker [stop]: Waiting 30 seconds for pods stopped with terminationGracePeriod:30"
    sleep 30
    echo "## Docker [stop]: Cleaning up after docker"
    docker ps -aq | xargs -r docker rm -f || true
    echo "## Docker [stop]: Waiting for docker to stop for 25 seconds"
    timeout 25 service docker stop || true

    # In total, we wait for 55s, add 5s for safety and we get to 60s. This
    # 60s value is what we set as the grace period on our prowjobs (see config.yaml).
fi

if [[ "${LOCAL_CACHE_ENABLED}" == "true" ]]; then
    if [[ $EXIT_VALUE == 0 ]]; then
        cache_unique_id="cache_$(date +"%F_H%H-M%M-S%S")_$(head -c 8 /proc/sys/kernel/random/uuid)"

        # 0. Make sure the local cache dir and the unique shared dir exist.
        mkdir -p "${LOCAL_CACHE_DIR}"
        mkdir -p "${SHARED_CACHE_DIR}/${cache_unique_id}"

        # 1. Copy the latest shared cache directory to the new shared directory that we are creating.
        #    This should be a same-disk rsync and should be fast. This forms the basis of the new cache.
        if [[ -f "${SHARED_CACHE_DIR}/latest" ]]; then
            latest_cache_dir=$(cat "${SHARED_CACHE_DIR}/latest")

            echo "## Local cache [update]: Copying latest cache to new cache directory ..."
            rsync -avv --inplace "${latest_cache_dir}/." "${SHARED_CACHE_DIR}/${cache_unique_id}"
        fi

        # 2. Copy the local cache directory to the new shared directory that we are creating. rsync
        #    will only copy the files that are not already present in the shared directory. The new
        #    shared directory now contains the latest cache + what was downloaded in the current job.
        echo "## Local cache [update]: Copying local cache to shared cache ..."
        rsync -avv --inplace "${LOCAL_CACHE_DIR}/." "${SHARED_CACHE_DIR}/${cache_unique_id}"

        # 3. Update the latest cache directory to the local cache directory.
        echo "## Local cache [update]: Updating latest cache directory to ${SHARED_CACHE_DIR}/${cache_unique_id}"
        echo "${SHARED_CACHE_DIR}/${cache_unique_id}" > "${SHARED_CACHE_DIR}/latest"

        # 4. Remove the old cache directories to save disk space. Keep the
        #    last 4 cache directories because they may be used by other
        #    jobs that are still copying from these directories.
        echo "## Local cache [update]: Removing old caches ..."
        find "${SHARED_CACHE_DIR}" -maxdepth 1 -type d -name 'cache_*' -printf '%f\n' | \
            sort -r | \
            tail -n +4 | \
            xargs -I{} rm -rf "${SHARED_CACHE_DIR}/{}"
    else
        echo "## Local cache [update]: Job failed, not updating cache."
    fi
fi

# preserve exit value from job / bootstrap
exit ${EXIT_VALUE}
